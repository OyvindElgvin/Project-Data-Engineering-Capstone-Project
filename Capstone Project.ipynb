{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# United States Immigration study\n",
    "\n",
    "## Data Engineering Capstone Project\n",
    "\n",
    "### Project Summary\n",
    "This project aims to unveil information about immigration into the United States. Questions like how the flow of immigrants changes seasonally, if the destinations are dependent on temperature, and where the immigrants come from are some of the key questions this study is trying to answer.\n",
    "\n",
    "Data are extracted from three different dataset sources, \"I94 Immigration Data\" from U.S. National Tourism and Trade Office, \"Global Land Temperatures By City\" from kaggle, and finally \"Us Cities Demographics\" from OpenSoft.\n",
    "\n",
    "Apache Spark, Jupyter Notebook, and potentially Amazon Elastic MapReduce, EMR, are used to accomplish this ETL pipeline, which then writes parquet files either to an Amazon S3 bucket or locally to disk.\n",
    "\n",
    "#### The project follows the following steps:\n",
    "- Step 1: Scope the Project and Gather Data\n",
    "- Step 2: Explore and Assess the Data\n",
    "- Step 3: Define the Data Model\n",
    "- Step 4: Run ETL to Model the Data\n",
    "- Step 5: Complete Project Write Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports and installs \n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col, udf, desc\n",
    "from pyspark.sql.types import StringType\n",
    "from IPython.display import display\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# makes pandas dataframe show every column\n",
    "pd.set_option('display.max_columns', 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "\n",
    "The scope for this project is to create a Data Lake using an ETL pipeline. This Jupyter Notebook presents the whole process, describing and assessing the datasets, and at the bottom, running the complete ETL pipeline.  Ideally, this notebook should run on an EMR cluster in AWS, especially if using the whole immigration dataset. For this study, the star schema is chosen, making it possible to execute the various queries outlined below.  \n",
    "\n",
    "\n",
    "### The choice of tools and technologies.\n",
    "\n",
    "Apache Spark and Jupyter Notebook are the primary processing tools for this ETL pipeline. The ability for Spark to handle vast amounts of data in parallel, and the fact that AWS EMR supports Spark out of the box, makes Spark a compelling choice. The Jupyter Notebook is not only a great choice as an interactive environment for writing and running code but also works well as a tool for documenting. \n",
    "\n",
    "\n",
    "#### Describing the datasets\n",
    "\n",
    "- **I94 Immigration Data**: comes from the [U.S. National Tourism and Trade Office](https://travel.trade.gov/research/reports/i94/historical/2016.html) and contains  \n",
    "various statistics on international visitor arrival in the USA and comes from the US National  \n",
    "Tourism and Trade Office. The dataset contains data from 2016.\n",
    "\n",
    "\n",
    "- **Temperature Data**: comes from [Kaggle](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) and is provided in a csv format, and includes  \n",
    "information like average temperature, date, and city.\n",
    "\n",
    "\n",
    "- **Demographic Data:** comes from [OpenSoft](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/) and contains information about the demographics of all US cities such as race, male and female population, and median age. This dataset is from 2015.\n",
    "\n",
    "\n",
    "#### This study tries to build an ETL and Data Model to answer the following questions:\n",
    "\n",
    "- What cities in the U.S. are the most common for arriving immigrants?\n",
    "- How does immigration change throughout a year?\n",
    "- Where do the immigrants come from?\n",
    "- What is the gender ratio for the immigrants?\n",
    "- What is the age profile for the volume of immigrants?\n",
    "- What is the legal status of immigrants in the U.S."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Gather Data\n",
    "\n",
    "The gathering of the data is done with pandas and spark dataFrames.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initializing SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "    .enableHiveSupport()\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set the write path to local or S3 bucket\n",
    "local = './results/'\n",
    "s3 = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Reading in Immigration Data to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading Immigration csv file to pandas\n"
     ]
    }
   ],
   "source": [
    "# read in the sample csv to pandas for easy assessing\n",
    "pd_immi_df = pd.read_csv('immigration_data_sample.csv')\n",
    "print('Finished reading Immigration csv file to pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160423</td>\n",
       "      <td>MTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "\n",
       "   i94mode i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup  \\\n",
       "0      1.0      HI  20573.0    61.0      2.0    1.0  20160422      NaN   NaN   \n",
       "1      1.0      TX  20568.0    26.0      2.0    1.0  20160423      MTR   NaN   \n",
       "2      1.0      FL  20571.0    76.0      2.0    1.0  20160407      NaN   NaN   \n",
       "\n",
       "  entdepa entdepd  entdepu matflag  biryear   dtaddto gender  insnum airline  \\\n",
       "0       G       O      NaN       M   1955.0  07202016      F     NaN      JL   \n",
       "1       G       R      NaN       M   1990.0  10222016      M     NaN     *GA   \n",
       "2       G       O      NaN       M   1940.0  07052016      M     NaN      LH   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  5.658267e+10  00782       WT  \n",
       "1  9.436200e+10  XBLNG       B2  \n",
       "2  5.578047e+10  00464       WT  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first look at the Immigration Data\n",
    "pd_immi_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Reading in Immigration Data to Spark\n",
    "This is to take advantage of the parallelization of spark, which pandas don't have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading Immigration sas.sample files to Spark.\n"
     ]
    }
   ],
   "source": [
    "# reading in either the full immigration data or a sample to spark\n",
    "\n",
    "# full imigration file, only use with EMR cluster\n",
    "# big_file = glob.glob(\"../../data/18-83510-I94-Data-2016/*.sas7bdat\")\n",
    "#                                                         ^\n",
    "\n",
    "# sample immigration file, only for April 2016\n",
    "small_file = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "\n",
    "# read in the data to Spark\n",
    "spark_immi_df =spark.read.format('com.github.saurfang.sas.spark').load(small_file)\n",
    "\n",
    "print('Finished reading Immigration sas.sample files to Spark.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>None</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20130811</td>\n",
       "      <td>SEO</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "\n",
       "   depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa entdepd  \\\n",
       "0      NaN    37.0      2.0    1.0      None     None  None       T    None   \n",
       "1      NaN    25.0      3.0    1.0  20130811      SEO  None       G    None   \n",
       "2  20691.0    55.0      2.0    1.0  20160401     None  None       T       O   \n",
       "\n",
       "  entdepu matflag  biryear   dtaddto gender insnum airline        admnum  \\\n",
       "0       U    None   1979.0  10282016   None   None    None  1.897628e+09   \n",
       "1       Y    None   1991.0       D/S      M   None    None  3.736796e+09   \n",
       "2    None       M   1961.0  09302016      M   None      OS  6.666432e+08   \n",
       "\n",
       "   fltno visatype  \n",
       "0   None       B2  \n",
       "1  00296       F1  \n",
       "2     93       B2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing with the spark Immigration Data\n",
    "spark_immi_df.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "It looks similar the immigration_data_sample.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Testing to see if everything works. Writing and reading the raw data, preferable to and from an S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing and reading\n"
     ]
    }
   ],
   "source": [
    "# test writing and reading parquet files\n",
    "spark_immi_df.write.parquet(\"sas_data\", 'overwrite')\n",
    "spark_immi_df = spark.read.parquet(\"sas_data\")\n",
    "print('Finished writing and reading')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Reading in Temperature Data to pandas\n",
    "The original file is unaccessible skip this step for the temperature data and use this instead: Temperature_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading Temperature Data to pandas\n"
     ]
    }
   ],
   "source": [
    "# reading in the Temperature Data to pandas\n",
    "pd_temp_df = pd.read_csv('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "print('Finished reading Temperature Data to pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first look at the Temperature Data\n",
    "pd_temp_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Reading in Demographic Data to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading Demographic Data to pandas\n"
     ]
    }
   ],
   "source": [
    "# reading in the Demographic Data to pandas\n",
    "pd_demo_df = pd.read_csv('us-cities-demographics.csv', sep = ';')\n",
    "print('Finished reading Demographic Data to pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring       Maryland        33.8          40601.0   \n",
       "1         Quincy  Massachusetts        41.0          44129.0   \n",
       "2         Hoover        Alabama        38.5          38040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "\n",
       "   Average Household Size State Code                Race  Count  \n",
       "0                    2.60         MD  Hispanic or Latino  25924  \n",
       "1                    2.39         MA               White  58723  \n",
       "2                    2.58         AL               Asian   4759  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first look at the Demographic Data\n",
    "pd_demo_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Exploration of the Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true,
    "toggleable": false,
    "ulab": {
     "buttons": {
      "ulab-button-toggle-4b8dc3dd": {
       "style": "primary"
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160423</td>\n",
       "      <td>MTR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160428</td>\n",
       "      <td>DOH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>721257</td>\n",
       "      <td>1481650.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20552.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>20606.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>10072016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DL</td>\n",
       "      <td>7.368526e+08</td>\n",
       "      <td>910</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1072780</td>\n",
       "      <td>2197173.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>20556.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20635.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>10112016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CX</td>\n",
       "      <td>7.863122e+08</td>\n",
       "      <td>870</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>112205</td>\n",
       "      <td>232708.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20546.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20554.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>06302016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.547449e+10</td>\n",
       "      <td>00117</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2577162</td>\n",
       "      <td>5227851.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>20575.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>07262016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LX</td>\n",
       "      <td>5.941342e+10</td>\n",
       "      <td>00008</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10930</td>\n",
       "      <td>13213.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>5.544979e+10</td>\n",
       "      <td>00109</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "5      721257  1481650.0  2016.0     4.0   577.0   577.0     ATL  20552.0   \n",
       "6     1072780  2197173.0  2016.0     4.0   245.0   245.0     SFR  20556.0   \n",
       "7      112205   232708.0  2016.0     4.0   113.0   135.0     NYC  20546.0   \n",
       "8     2577162  5227851.0  2016.0     4.0   131.0   131.0     CHI  20572.0   \n",
       "9       10930    13213.0  2016.0     4.0   116.0   116.0     LOS  20545.0   \n",
       "\n",
       "   i94mode i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup  \\\n",
       "0      1.0      HI  20573.0    61.0      2.0    1.0  20160422      NaN   NaN   \n",
       "1      1.0      TX  20568.0    26.0      2.0    1.0  20160423      MTR   NaN   \n",
       "2      1.0      FL  20571.0    76.0      2.0    1.0  20160407      NaN   NaN   \n",
       "3      1.0      CA  20581.0    25.0      2.0    1.0  20160428      DOH   NaN   \n",
       "4      3.0      NY  20553.0    19.0      2.0    1.0  20160406      NaN   NaN   \n",
       "5      1.0      GA  20606.0    51.0      2.0    1.0  20160408      NaN   NaN   \n",
       "6      1.0      CA  20635.0    48.0      2.0    1.0  20160412      NaN   NaN   \n",
       "7      1.0      NY  20554.0    33.0      2.0    1.0  20160402      NaN   NaN   \n",
       "8      1.0      IL  20575.0    39.0      2.0    1.0  20160428      NaN   NaN   \n",
       "9      1.0      CA  20553.0    35.0      2.0    1.0  20160401      NaN   NaN   \n",
       "\n",
       "  entdepa entdepd  entdepu matflag  biryear   dtaddto gender  insnum airline  \\\n",
       "0       G       O      NaN       M   1955.0  07202016      F     NaN      JL   \n",
       "1       G       R      NaN       M   1990.0  10222016      M     NaN     *GA   \n",
       "2       G       O      NaN       M   1940.0  07052016      M     NaN      LH   \n",
       "3       G       O      NaN       M   1991.0  10272016      M     NaN      QR   \n",
       "4       Z       K      NaN       M   1997.0  07042016      F     NaN     NaN   \n",
       "5       T       N      NaN       M   1965.0  10072016      M     NaN      DL   \n",
       "6       T       O      NaN       M   1968.0  10112016      F     NaN      CX   \n",
       "7       G       O      NaN       M   1983.0  06302016      F     NaN      BA   \n",
       "8       O       O      NaN       M   1977.0  07262016    NaN     NaN      LX   \n",
       "9       O       O      NaN       M   1981.0  06292016    NaN     NaN      AA   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  5.658267e+10  00782       WT  \n",
       "1  9.436200e+10  XBLNG       B2  \n",
       "2  5.578047e+10  00464       WT  \n",
       "3  9.478970e+10  00739       B2  \n",
       "4  4.232257e+10   LAND       WT  \n",
       "5  7.368526e+08    910       B2  \n",
       "6  7.863122e+08    870       B2  \n",
       "7  5.547449e+10  00117       WT  \n",
       "8  5.941342e+10  00008       WT  \n",
       "9  5.544979e+10  00109       WT  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overview of the Immigration Data\n",
    "pd_immi_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    1000\n",
       "cicid         1000\n",
       "i94yr         1000\n",
       "i94mon        1000\n",
       "i94cit        1000\n",
       "i94res        1000\n",
       "i94port       1000\n",
       "arrdate       1000\n",
       "i94mode       1000\n",
       "i94addr        941\n",
       "depdate        951\n",
       "i94bir        1000\n",
       "i94visa       1000\n",
       "count         1000\n",
       "dtadfile      1000\n",
       "visapost       382\n",
       "occup            4\n",
       "entdepa       1000\n",
       "entdepd        954\n",
       "entdepu          0\n",
       "matflag        954\n",
       "biryear       1000\n",
       "dtaddto       1000\n",
       "gender         859\n",
       "insnum          35\n",
       "airline        967\n",
       "admnum        1000\n",
       "fltno          992\n",
       "visatype      1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting non-NaNs for each column\n",
    "pd_immi_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The column abbreviations are explained in the **I94_SAS_Labels_Descriptions.SAS** file and is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "  table {margin-left: 0 !important;}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "  table {margin-left: 0 !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Abbreviation | Description |\n",
    "|------------|------------|  \n",
    "|cicid     |    Immigrant ID number|\n",
    "|i94yr     |    Year  |\n",
    "|i94mon    |    Month  |\n",
    "|i94cit    |    Which city they came from  \n",
    "i94res     |   Which country they came from\n",
    "i94port    |   Airport at arrival\n",
    " arrdate    |   Arrival Date in the USA  \n",
    " i94mode    |   Mode of transportation to the USA  \n",
    " i94addr    |   Address state  \n",
    " depdate    |   Departure Date from the USA  \n",
    " i94bir     |   Age of Respondent in Years  \n",
    "| i94visa   |   Reasons for immigration: <br /> 1 = Business <br /> 2 = Pleasure <br /> 3 = Student |\n",
    " count      |   Used for summary statistics  \n",
    " dtadfile   |   Date added to I-94 Files  \n",
    " visapost   |   Department of State where where Visa was issued  \n",
    " entdepa    |   Admitted or paroled into the U.S.  \n",
    " entdepd    |   Departed  \n",
    " matflag    |   Match of arrival and departure records  \n",
    " biryear    |   Year of birth  \n",
    " dtaddto    |   Date to which admitted to U.S. (allowed to stay until)  \n",
    " gender     |   Gender  \n",
    " airline    |   Airline used to arrive in U.S.  \n",
    " admnum     |   Admission Number  \n",
    " fltno      |   Flight number of Airline used to arrive in U.S.  \n",
    " visatype   |   Class of admission legally admitting the <br /> non-immigrant to temporarily stay in U.S.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's take a look at the **visatype** column. What types are there, and what do they mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|visatype|  count|\n",
      "+--------+-------+\n",
      "|      WT|1309059|\n",
      "|      B2|1117897|\n",
      "|      WB| 282983|\n",
      "|      B1| 212410|\n",
      "|     GMT|  89133|\n",
      "|      F1|  39016|\n",
      "|      E2|  19383|\n",
      "|      CP|  14758|\n",
      "|      E1|   3743|\n",
      "|       I|   3176|\n",
      "|      F2|   2984|\n",
      "|      M1|   1317|\n",
      "|      I1|    234|\n",
      "|     GMB|    150|\n",
      "|      M2|     49|\n",
      "|     SBP|     11|\n",
      "|     CPL|     10|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# counting each visatype\n",
    "spark_immi_df.groupBy('visatype').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Where \n",
    "- WT - Visitors entering for pleasure\n",
    "- B2 - Visitors (\"tourists\"): Temporary Visitor for Pleasure or Medical Treatment\n",
    "- WB - Visitors entering for business purposes\n",
    "- B1 - Temporary Visa for Business Travelers and domestic servant  \n",
    "...  \n",
    "[See more here](https://travel.state.gov/content/travel/en/us-visas/visa-information-resources/all-visa-categories.html)\n",
    "\n",
    "The **visatype** looks good, so I'll just leave the visa type as it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing schema\n",
    "spark_immi_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The data types look acceptable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Checking the **i94mode** column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# creating a temporary spark sql table view\n",
    "spark_immi_df.createOrReplaceTempView('immi_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|i94mode|count(1)|\n",
      "+-------+--------+\n",
      "|    1.0| 2994505|\n",
      "|    3.0|   66660|\n",
      "|    2.0|   26349|\n",
      "|    9.0|    8560|\n",
      "|   null|     239|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT i94mode, count(*)\n",
    "FROM immi_table\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "where:\n",
    "\n",
    "1 = Air <br />\n",
    "2 = Sea <br />\n",
    "3 = Land <br />\n",
    "9 = Not reported  <br />\n",
    "\n",
    "To keep the data consistent with airports, only the travels by air are kept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Checking to see if **cicid** can be used as a primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|total_amount_rows|\n",
      "+-----------------+\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# taking the total amount of rows minus the amount of distinct cicid rows\n",
    "# if 0, then cicid can be used as a primary key. \n",
    "spark.sql(\"\"\"\n",
    "SELECT count(*) AS total_amount_rows\n",
    "FROM immi_table\n",
    "\n",
    "MINUS\n",
    "\n",
    "SELECT COUNT(DISTINCT(cicid)) AS distinct_rows_cicid\n",
    "FROM immi_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since every row in cicid is distinct, cicid can be used as a primary key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The **i94visa** column, or the reason for immigration, is divided into three categories: <br /> 1 = Business <br /> 2 = Pleasure <br /> 3 = Student  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|i94visa|count(1)|\n",
      "+-------+--------+\n",
      "|    2.0| 2530868|\n",
      "|    1.0|  522079|\n",
      "|    3.0|   43366|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# counting numbers of records for each reason for immigration\n",
    "spark.sql(\"\"\"\n",
    "SELECT i94visa, count(*)\n",
    "FROM immi_table\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|gender|  count|\n",
      "+------+-------+\n",
      "|     M|1377224|\n",
      "|     F|1302743|\n",
      "|  null| 414269|\n",
      "|     X|   1610|\n",
      "|     U|    467|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check the gender column\n",
    "spark_immi_df.groupby('gender').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Only 'M' and 'F' **genders** will be kept. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|i94bir|count|\n",
      "+------+-----+\n",
      "| 114.0|    1|\n",
      "| 111.0|    1|\n",
      "| 110.0|    1|\n",
      "| 109.0|    2|\n",
      "| 108.0|    2|\n",
      "| 107.0|    1|\n",
      "| 105.0|    2|\n",
      "| 103.0|    1|\n",
      "| 102.0|    4|\n",
      "| 101.0|    2|\n",
      "| 100.0|   24|\n",
      "|  99.0|   19|\n",
      "|  98.0|   26|\n",
      "|  97.0|   52|\n",
      "|  96.0|   46|\n",
      "|  95.0|   88|\n",
      "|  94.0|  104|\n",
      "|  93.0|  185|\n",
      "|  92.0|  241|\n",
      "|  91.0|  319|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# counting the number of each age\n",
    "spark_immi_df.groupby('i94bir').count().orderBy('i94bir', ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "That a 114 year old has immigrated seems a bit strange, so I'll cap the age at 105. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The codes in **i94cit** and **i94res** columns needs to be replaced with the corresponding city and country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The **i94port** column shows the airports the immigrants arrived at, but to keep it compatible with dimension tables I will map the airport to two new columns, **'arrival_city'** and **'arrival_state'**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Explore the Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1744-04-01</td>\n",
       "      <td>5.788</td>\n",
       "      <td>3.624</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1744-05-01</td>\n",
       "      <td>10.644</td>\n",
       "      <td>1.283</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1744-06-01</td>\n",
       "      <td>14.051</td>\n",
       "      <td>1.347</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1744-07-01</td>\n",
       "      <td>16.082</td>\n",
       "      <td>1.396</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1744-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "5  1744-04-01               5.788                          3.624  Århus   \n",
       "6  1744-05-01              10.644                          1.283  Århus   \n",
       "7  1744-06-01              14.051                          1.347  Århus   \n",
       "8  1744-07-01              16.082                          1.396  Århus   \n",
       "9  1744-08-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  \n",
       "5  Denmark   57.05N    10.33E  \n",
       "6  Denmark   57.05N    10.33E  \n",
       "7  Denmark   57.05N    10.33E  \n",
       "8  Denmark   57.05N    10.33E  \n",
       "9  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first look at the temperatur data\n",
    "pd_temp_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2013-09-01'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting the latest date\n",
    "pd_temp_df['dt'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "It looks like there is a measurement every month, but the dataset stops at '2013-09-01'. Since it, therefore, won't match with the immigrant data I'll go ahead and do the stupid thing and add 4 years to the 2012 records so that it matches up to the immigration records. It's not perfect, but I think it is a viable solution. I'll also filter for only the year 2012. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which countries are in the data\n",
    "pd_temp_df['Country'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This study is also only looking at US data, so the other 158 countrys should be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# filtering records for the US\n",
    "pd_temp_df = pd_temp_df[pd_temp_df['Country'] == 'United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                               687289\n",
       "AverageTemperature               661524\n",
       "AverageTemperatureUncertainty    661524\n",
       "City                             687289\n",
       "Country                          687289\n",
       "Latitude                         687289\n",
       "Longitude                        687289\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking NaNs\n",
    "pd_temp_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "NaNs in 'AverageTemperature' need to be dropped. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "City names letter case should match the letter case for city in the immigration table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing csv file\n"
     ]
    }
   ],
   "source": [
    "# writing to csv for reproducibility\n",
    "pd_temp_df.to_csv('Temperature_data.csv', index = False)\n",
    "print('Finished writing csv file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Explore the Demographics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overview of the Demographic Data\n",
    "pd_demo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                      2891\n",
       "State                     2891\n",
       "Median Age                2891\n",
       "Male Population           2888\n",
       "Female Population         2888\n",
       "Total Population          2891\n",
       "Number of Veterans        2878\n",
       "Foreign-born              2878\n",
       "Average Household Size    2875\n",
       "State Code                2891\n",
       "Race                      2891\n",
       "Count                     2891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the nonNaNs for each column\n",
    "pd_demo_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "City names letter case should once again match the letter case for city in the immigration table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# dropping the NaNs in every column\n",
    "pd_demo_df = pd_demo_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                      2875\n",
       "State                     2875\n",
       "Median Age                2875\n",
       "Male Population           2875\n",
       "Female Population         2875\n",
       "Total Population          2875\n",
       "Number of Veterans        2875\n",
       "Foreign-born              2875\n",
       "Average Household Size    2875\n",
       "State Code                2875\n",
       "Race                      2875\n",
       "Count                     2875\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting again to see how many NaNs got dropped\n",
    "pd_demo_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Should drop NaNs to keep the data clean.  \n",
    "Checking to see if City and State can be used as a composite key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City     588\n",
       "State    588\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping duplicates to see how many distinct values there are\n",
    "pd_demo_df[['City', 'State']].drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City     2875\n",
       "State    2875\n",
       "Race     2875\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maybe three columns would be more suitable\n",
    "pd_demo_df[['City', 'State', 'Race']].drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Yes, that'll do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "As explained in the scope of the project, the Data Model is a Data Lake leading into a star schema. As opposed to a Data Warehouse, where each schema is normalized and tailored to a specific query through the 'schema-on-write' approach, the Data Lake uses a 'schema-on-read' approach, which gives more flexibility to what queries could be made. \n",
    "\n",
    "To meet the requirements for the scope of the project a star schema with two dimensions is being made. The fact table consists of facts about the immigrants, and the two dimension tables will store information about temperatures per month per city and demographics for each city. This setup will hopefully allow analysts to make queries that answer the questions presented in the scope of the project. \n",
    "\n",
    "A diagram of the star schema is presented below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "![picss](./Table_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Immigration fact table\n",
    "- id\n",
    "- arrival_city\n",
    "- arrival_state\n",
    "- arrival_date\n",
    "- departure_date\n",
    "- year\n",
    "- month\n",
    "- country_citizenship\n",
    "- country_residence\n",
    "- age\n",
    "- gender\n",
    "- reason_for_immigration\n",
    "- visatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperature dimension table\n",
    "- city\n",
    "- date\n",
    "- year_plus_4_years\n",
    "- month\n",
    "- average_temperature\n",
    "- average_temperature_uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Demographics dimension table\n",
    "- city\n",
    "- state_code\n",
    "- race\n",
    "- median_age\n",
    "- male_population\n",
    "- total_population\n",
    "- number_of_veterans\n",
    "- foreign_born\n",
    "- average_household\n",
    "- count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3.2 Mapping Out Data Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Transformation steps for the Immigration Data\n",
    "- Date values needs to be transformed to YYYY-MM-DD.\n",
    "- Port values needs validating. \n",
    "- States needs to correspond to the state codes in the Demographic Data.\n",
    "- Filter i94visa column by mode of transportation to only let travel by air.\n",
    "- Set the reasons for immigration.\n",
    "- Filter genders.\n",
    "- Capping age at 105\n",
    "- Convert i94res codes to new country_residence column\n",
    "- Convert i94cit codes to new country_citizenship column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperature Data transforming steps\n",
    "- Filter for only US using pandas\n",
    "- Drop rows with NaN in AverageTemperature column\n",
    "- Convert dt to datetime\n",
    "- Only keep records from 2013\n",
    "- For each city keep only one records per day \n",
    "- Make city names upper case to match fact table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Demographic Data transforming steps\n",
    "- Make city names upper case\n",
    "- Drop NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The ETL pipeline will consist of the following sections:\n",
    "- #### Extraction\n",
    "    - Extraction of csv and sas files\n",
    "    - Extraction for dictionaries from the I94_SAS_Labels_Descriptions\n",
    "- #### Transformation\n",
    "    - Transforming of the Immigration Data\n",
    "    - Transforming of the Temperature Data\n",
    "    - Transforming of the Demographic Data\n",
    "- #### Loading\n",
    "    - Loading of the data to S3 or locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished extracting data\n"
     ]
    }
   ],
   "source": [
    "# extracting a fresh set of data\n",
    "\n",
    "pd_temperature = pd.read_csv('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "pd_demographic = pd.read_csv('us-cities-demographics.csv', sep = ';')\n",
    "spark_immigration =spark.read.format('com.github.saurfang.sas.spark')\\\n",
    "                             .load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "print('Finished extracting data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Extracting data from I94_SAS_Labels_Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# reading in the data from the Labels_Descriptions file\n",
    "i94_sas_label_descriptions_fname = \"I94_SAS_Labels_Descriptions.SAS\"\n",
    "\n",
    "# reading in all the lines\n",
    "with open(i94_sas_label_descriptions_fname) as f:\n",
    "    Labels_Descriptions = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# creating dictionaries\n",
    "\n",
    "\n",
    "# making a dictionary with {ports: [city, state]} from the Labels_Descriptions file\n",
    "re_compiled = re.compile(r\"\\'(.*)\\'.*\\'(.*)\\'\")\n",
    "valid_ports = {}\n",
    "for line in Labels_Descriptions[302:962]:\n",
    "    results = re_compiled.search(line)\n",
    "    key = results[1]\n",
    "    value = results[2].split(\",\")\n",
    "    if len(value) == 2:\n",
    "        value[1] = value[1].strip(' ')\n",
    "        valid_ports[key] = value\n",
    "    else:\n",
    "        valid_ports[key] = value\n",
    "\n",
    "# valid_ports:\n",
    "\n",
    "# {'ALC': ['ALCAN', 'AK'],\n",
    "#  'ANC': ['ANCHORAGE', 'AK'],\n",
    "#  'BAR': ['BAKER AAF - BAKER ISLAND', 'AK'],\n",
    "#  'DAC': ['DALTONS CACHE', 'AK'], \n",
    "#   ...\n",
    "\n",
    "        \n",
    "# making a dictionary with country codes from the Labels_Descriptions file\n",
    "re_compiled = re.compile(r\"\\   (.*)\\ =.*\\'(.*)\\'\")\n",
    "country_codes = {}\n",
    "for line in Labels_Descriptions[9:298]:\n",
    "    results = re_compiled.search(line)\n",
    "    country_codes[int(results[1])] = results[2]\n",
    "    \n",
    "# country_codes:    \n",
    "\n",
    "# {582: 'MEXICO',\n",
    "#  236: 'AFGHANISTAN',\n",
    "#  101: 'ALBANIA',\n",
    "#  316: 'ALGERIA',\n",
    "#  ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Transforming the Immigration Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Transformation steps for the Immigration Data\n",
    "- Date values needs to be transformed to YYYY-MM-DD.\n",
    "- Port values needs validating. \n",
    "- States needs to correspond to the state codes in the Demographic Data.\n",
    "- Filter i94visa column by mode of transportation to only let travel by air.\n",
    "- Set the reasons for immigration.\n",
    "- Filter genders.\n",
    "- Capping age at 105\n",
    "- Convert i94res codes to new country_residence column\n",
    "- Convert i94cit codes to new country_citizenship column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# number of rows in the original data\n",
    "# spark_immigration.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The SAS System represents dates as the [number of days since a reference date](http://v8doc.sas.com/sashtml/ets/chap2/sect5.htm#:~:text=SAS%20date%20values%20are%20written,value%20for%2017%20October%201991.). The reference date, or date zero, used for SAS date values is 1 January 1960. Thus, for example, 3 February 1960 is represented by the SAS System as 33."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# transforming the arrdate column\n",
    "\n",
    "# create udf to convert SAS date to YYYY-MM-DD\n",
    "@udf(StringType())\n",
    "def date_to_isoformat(x):\n",
    "    \"\"\"\n",
    "    argument: SAS system date\n",
    "    return: datetime YYYY-MM-DD\n",
    "    \n",
    "    This function takes the 'date zero' and adds the number of days\n",
    "    delivered in the argument.\n",
    "    \"\"\"\n",
    "\n",
    "    if x:\n",
    "        \n",
    "        return (datetime(1960, 1, 1).date() + timedelta(x)).isoformat()\n",
    "    return None\n",
    "\n",
    "# convert sas date to spark dates in column arrdate and depdate\n",
    "spark_immigration = spark_immigration.withColumn('arrdate', date_to_isoformat(spark_immigration.arrdate))\n",
    "spark_immigration = spark_immigration.withColumn('depdate', date_to_isoformat(spark_immigration.depdate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "[Link to regex page](https://regex101.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# generating the arrival_city column\n",
    "\n",
    "# valid_ports:\n",
    "# {'ALC': ['ALCAN', 'AK'],\n",
    "# ...\n",
    "\n",
    "\n",
    "@udf(StringType())\n",
    "def port_to_city(port):\n",
    "    \"\"\"\n",
    "    argument: airport\n",
    "    return: city\n",
    "    \n",
    "    this function takes a port abbreviation as argument and \n",
    "    return a corresponding city from the valid_ports dict\n",
    "    \n",
    "    \"\"\"\n",
    "    if port in valid_ports:\n",
    "        return valid_ports[port][0]\n",
    "    return None\n",
    "    \n",
    "\n",
    "# generating an arrival_city column with the city names from valid_ports dictionary\n",
    "spark_immigration = spark_immigration.withColumn('arrival_city', port_to_city(spark_immigration.i94port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# removing null values from arrival_city column\n",
    "spark_immigration = spark_immigration.filter('arrival_city is not null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# generating the arrival_state column\n",
    "\n",
    "# valid_ports:\n",
    "# {'ALC': ['ALCAN', 'AK'],\n",
    "#  'WAS': [WASHINGTON DC],\n",
    "#  ...\n",
    "\n",
    "\n",
    "\n",
    "@udf(StringType())\n",
    "def port_to_state(port):\n",
    "    \"\"\"\n",
    "    argument: (string) airport\n",
    "    return: (string) state\n",
    "    \n",
    "    This function maps the airport to state\n",
    "    \"\"\"\n",
    "    \n",
    "    if port in valid_ports:\n",
    "        # exception where:\n",
    "        #          city == state\n",
    "        # WASHINGTON DC == WASHINGTON DC\n",
    "        # so when:\n",
    "        # if len(valid_ports['WAS']) = 1: \n",
    "        #     then state == city\n",
    "        \n",
    "        if len(valid_ports[port]) == 2:\n",
    "            return valid_ports[port][1]\n",
    "        else:\n",
    "            return valid_ports[port][0]\n",
    "\n",
    "\n",
    "# generating a arrival_state column with state names\n",
    "spark_immigration = spark_immigration.withColumn('arrival_state', port_to_state(spark_immigration.i94port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# creating a temporary spark sql table view\n",
    "spark_immigration.createOrReplaceTempView('immigration_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# keep only those that travelled by air\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM immigration_table\n",
    "WHERE i94mode == 1.0\n",
    "\"\"\").createOrReplaceTempView('immigration_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set the reason for immigrating\n",
    "spark.sql(\"\"\"\n",
    "SELECT *, CASE  \n",
    "               WHEN i94visa = 1 THEN 'Business'\n",
    "               WHEN i94visa = 2 THEN 'Pleasure'\n",
    "               WHEN i94visa = 3 THEN 'Student'\n",
    "               ELSE NULL END as reason_for_immigration\n",
    "               \n",
    "FROM immigration_table\"\"\").createOrReplaceTempView('immigration_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# filter gender for only male and female\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM immigration_table\n",
    "WHERE gender IN ('M', 'F')\n",
    "\"\"\").createOrReplaceTempView('immigration_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# capping the age at 105\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM immigration_table\n",
    "WHERE i94bir <= 105.0\n",
    "\"\"\").createOrReplaceTempView('immigration_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# creating a temporary table view of the country_codes  \n",
    "\n",
    "# making a pandas df from country codes, I think this is the best way to get in a spark dataframe\n",
    "pd_df_country_codes = pd.DataFrame(list(country_codes.items()),columns = ['country_codes', 'country']) \n",
    "\n",
    "# creating a spark dataframe from the pandas dataframe\n",
    "spark_df_country_codes = spark.createDataFrame(pd_df_country_codes)\n",
    "\n",
    "# creating a temporary spark sql table view\n",
    "spark_df_country_codes.createOrReplaceTempView(\"country_codes_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# adding a country_residence column with country names from the i94res codes\n",
    "spark.sql(\"\"\"\n",
    "SELECT im.*, cc.country AS country_residence\n",
    "FROM immigration_table im\n",
    "JOIN country_codes_table cc\n",
    "ON im.i94res = cc.country_codes\n",
    "\"\"\").createOrReplaceTempView('immigration_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# adding a country_citizenship column with country names from the 94cit codes\n",
    "spark.sql(\"\"\"\n",
    "SELECT im.*, cc.country AS country_citizenship\n",
    "FROM immigration_table im\n",
    "JOIN country_codes_table cc\n",
    "ON im.i94cit = cc.country_codes\n",
    "\"\"\").createOrReplaceTempView('immigration_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# creating immigration fact table\n",
    "fact_immigration = spark.sql(\"\"\"\n",
    "                                        SELECT \n",
    "                                                cicid AS id,\n",
    "                                                arrival_city,\n",
    "                                                arrival_state,\n",
    "                                                arrdate AS arrival_date,\n",
    "                                                depdate AS departure_date,\n",
    "                                                i94yr AS year,\n",
    "                                                i94mon AS month,\n",
    "                                                country_citizenship,\n",
    "                                                country_residence,\n",
    "                                                i94bir AS age,\n",
    "                                                gender,\n",
    "                                                reason_for_immigration,\n",
    "                                                visatype\n",
    "\n",
    "                                        FROM immigration_table\n",
    "                                   \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# counting the number of rows\n",
    "# fact_immigration.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# test to see how the fact_immigration_table turned out\n",
    "fact_immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Transforming the Temperature Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperature Data transforming steps\n",
    "- Filter for only US using pandas\n",
    "- Drop rows with NaN in AverageTemperature column\n",
    "- Convert dt to datetime\n",
    "- Only keep temperatures between 2012 and 2013\n",
    "- Add four years to the reacords to make them match immigration records\n",
    "- For each city keep only one records per day \n",
    "- Make city names upper case to match fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pd_temperature.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# only keep the temperatures for US\n",
    "pd_temperature = pd_temperature[pd_temperature['Country'] == 'United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# drop rows with NaN in AverageTemperature\n",
    "pd_temperature = pd_temperature.dropna(how = 'any', subset = ['AverageTemperature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert dt to datetime\n",
    "pd_temperature['date'] = pd.to_datetime(pd_temperature.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# only keep temperatures between 2012 and 2013\n",
    "dates = (pd_temperature['date'] >= '2012-01-01') & (pd_temperature['date'] < '2013-01-01')\n",
    "pd_temperature = pd_temperature.loc[dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# adding 4 years to the temperature measurements to get them to 2016\n",
    "pd_temperature['date'] = pd_temperature['date'] + pd.DateOffset(years=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# adding a year column\n",
    "pd_temperature['year'] = pd.DatetimeIndex(pd_temperature['date']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# adding a month column\n",
    "pd_temperature['month'] = pd.DatetimeIndex(pd_temperature['date']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# only keeping one temperature per day for each city\n",
    "pd_temperature = pd_temperature.drop_duplicates(['date', 'City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# making the city names upper case\n",
    "pd_temperature.City = pd_temperature['City'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# creating a temporary spark sql table view of the pandas dataframe\n",
    "spark_temperature = spark.createDataFrame(pd_temperature)\n",
    "spark_temperature.createOrReplaceTempView('temperature_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# creating the dimensional temperature table\n",
    "dim_temperature = spark.sql(\"\"\"\n",
    "                                SELECT \n",
    "                                        DISTINCT\n",
    "                                        date, \n",
    "                                        year AS year_plus_4_years,\n",
    "                                        month,\n",
    "                                        City AS city,\n",
    "                                        AVG(AverageTemperature) OVER (PARTITION BY City, date) AS average_temperature,\n",
    "                                        AVG(AverageTemperatureUncertainty) OVER (PARTITION BY City, date) AS average_temperature_uncertainty\n",
    "                                        \n",
    "                                FROM temperature_table\n",
    "                            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# counting number of rows\n",
    "# dim_temperature.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Checking out the temperatur table\n",
    "dim_temperature.orderBy('city', 'date').limit(13).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Transforming the Demographic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Demographic Data transforming steps\n",
    "- Make city names upper case\n",
    "- Drop NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pd_demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# making the city names upper case\n",
    "pd_demographic.City = pd_demographic['City'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# dropping NaNs in all columns\n",
    "pd_demographic = pd_demographic.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# creating a temporary spark sql table view from pandas\n",
    "spark_demographic = spark.createDataFrame(pd_demographic)\n",
    "spark_demographic.createOrReplaceTempView('demographic_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# creating the dimensional demographic table\n",
    "dim_demographic = spark.sql(\"\"\"\n",
    "                                SELECT \n",
    "                                        City AS city,\n",
    "                                       `State Code` AS state_code,\n",
    "                                        Race AS race,\n",
    "                                       `Median Age` AS median_age,\n",
    "                                       `Male Population` AS male_population,\n",
    "                                       `Total Population` AS total_population,\n",
    "                                       `Number of Veterans` AS number_of_veterans,\n",
    "                                       `Foreign-born` AS foreign_born,\n",
    "                                       `Average Household Size` AS average_household,\n",
    "                                        Count AS count\n",
    "\n",
    "                                FROM demographic_table\n",
    "                            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# counting number of rows\n",
    "# dim_demographic.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Checking out the demographic table\n",
    "dim_demographic.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Loading the Data\n",
    "The data should preferably be loaded into an S3 bucket for further analysis, but for this demonstration with only one month of data, writing it locally to disk will suffice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing tables to disk\n"
     ]
    }
   ],
   "source": [
    "# writing the tables as parquet files to either locally or s3\n",
    "\n",
    "fact_immigration.write.mode('overwrite').parquet(local + 'fact_immigration.parquet')\n",
    "dim_temperature.write.mode('overwrite').parquet(local + 'dim_temperature.parquet')\n",
    "dim_demographic.write.mode('overwrite').parquet(local + 'dim_demographic.parquet')\n",
    "        \n",
    "print('Finished writing tables to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.2 Data Quality Checks\n",
    "Two unit tests and two Data Quality tests are deployed below. The unit tests are testing the functions 'date_to_isoformat' and 'port_to_state'. \n",
    "\n",
    "The first Data Quality test is to validate if the tables exist and have any records, and the second is to detect NaNs in the primary keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# loading a sample of the Immigration Data into spark to use in the data quality checks\n",
    "# using inferSchema = \"true\" to set the column data type the same as the values own data type\n",
    "TEST_Im = spark.read.format('csv').options(header = 'true', inferSchema = \"true\")\\\n",
    "                             .load('immigration_data_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>visapost</th>\n",
       "      <th>occup</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160422</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160423</td>\n",
       "      <td>MTR</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>R</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160407</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160428</td>\n",
       "      <td>DOH</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       _c0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0  2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1  2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2   589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3  2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "\n",
       "   i94mode i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup  \\\n",
       "0      1.0      HI  20573.0    61.0      2.0    1.0  20160422     None  None   \n",
       "1      1.0      TX  20568.0    26.0      2.0    1.0  20160423      MTR  None   \n",
       "2      1.0      FL  20571.0    76.0      2.0    1.0  20160407     None  None   \n",
       "3      1.0      CA  20581.0    25.0      2.0    1.0  20160428      DOH  None   \n",
       "\n",
       "  entdepa entdepd entdepu matflag  biryear   dtaddto gender insnum airline  \\\n",
       "0       G       O    None       M   1955.0  07202016      F   None      JL   \n",
       "1       G       R    None       M   1990.0  10222016      M   None     *GA   \n",
       "2       G       O    None       M   1940.0  07052016      M   None      LH   \n",
       "3       G       O    None       M   1991.0  10272016      M   None      QR   \n",
       "\n",
       "         admnum  fltno visatype  \n",
       "0  5.658267e+10  00782       WT  \n",
       "1  9.436200e+10  XBLNG       B2  \n",
       "2  5.578047e+10  00464       WT  \n",
       "3  9.478970e+10  00739       B2  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overview of the original immigration data\n",
    "TEST_Im.limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING the function date_to_isoformat:\n",
      "UNIT TEST PASSED!\n"
     ]
    }
   ],
   "source": [
    "# TESTING the function date_to_isoformat\n",
    "print('TESTING the function date_to_isoformat:')\n",
    "\n",
    "# replacing columns 'arrdate' and 'depdate' \n",
    "# with date_to_isoformat function\n",
    "TEST_Im = TEST_Im.withColumn('arrdate', date_to_isoformat(TEST_Im.arrdate))\n",
    "TEST_Im = TEST_Im.withColumn('depdate', date_to_isoformat(TEST_Im.depdate))\n",
    "\n",
    "if TEST_Im.first()[7] == '2016-04-22' and TEST_Im.first()[10] == '2016-04-29':\n",
    "    print('UNIT TEST PASSED!')\n",
    "else:\n",
    "    raise ValueError(f'''UNIT TEST FAILED! Giving {TEST_Im.first()[7]} instead of \"2016-04-22\"\n",
    "                                              and {TEST_Im.first()[10]} instead of \"2016-04-29\"''')\n",
    "    \n",
    "# TEST_Im.select('arrdate', 'depdate').limit().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING the function port_to_state:\n",
      "UNIT TEST PASSED!\n"
     ]
    }
   ],
   "source": [
    "# TESTING the function port_to_state\n",
    "print('TESTING the function port_to_state:')\n",
    "\n",
    "# creating columns 'arrival_city' and 'arrival_state' \n",
    "# with port_to_city function\n",
    "TEST_Im = TEST_Im.withColumn('arrival_city', port_to_city(TEST_Im.i94port))\n",
    "TEST_Im = TEST_Im.withColumn('arrival_state', port_to_state(TEST_Im.i94port))\n",
    "\n",
    "if TEST_Im.first()[29] == 'HONOLULU' and TEST_Im.first()[30] == 'HI':\n",
    "    print('UNIT TEST PASSED!')\n",
    "else:\n",
    "    raise ValueError(f'''UNIT TEST FAILED! Giving {TEST_Im.first()[29]} instead of \"HONOLULU\"\n",
    "                         and {TEST_Im.first()[30]} instead of \"HI\"''')\n",
    "\n",
    "# TEST_Im.select('arrival_city', 'arrival_state').limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrdate</th>\n",
       "      <th>depdate</th>\n",
       "      <th>arrival_city</th>\n",
       "      <th>arrival_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>HONOLULU</td>\n",
       "      <td>HI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>MCALLEN</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>KAHULUI - MAUI</td>\n",
       "      <td>HI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>2016-05-07</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      arrdate     depdate    arrival_city arrival_state\n",
       "0  2016-04-22  2016-04-29        HONOLULU            HI\n",
       "1  2016-04-23  2016-04-24         MCALLEN            TX\n",
       "2  2016-04-07  2016-04-27  KAHULUI - MAUI            HI\n",
       "3  2016-04-28  2016-05-07     LOS ANGELES            CA"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the result of both funcions that got unit tested\n",
    "TEST_Im.select('arrdate', 'depdate', 'arrival_city', 'arrival_state').limit(4).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for tables existence.\n",
      "TEST PASSED! The dim_temperature table exists with 2976 number of records\n",
      "TEST PASSED! The dim_demographic table exists with 2875 number of records\n",
      "TEST PASSED! The fact_immigration table exists with 2263563 number of records\n"
     ]
    }
   ],
   "source": [
    "# TESTING to check if the DataFrames have any rows\n",
    "\n",
    "def exists(df, table_name):\n",
    "    \"\"\"\n",
    "    Arguments: DataFrame, name_of_DataFrame \n",
    "    \n",
    "    If the number of rows are more than 0 the test passed\n",
    "    If the number of rows are 0 the test failed and a ValueError is raised\n",
    "    \"\"\"\n",
    "    res = df.count()\n",
    "    if res > 0:\n",
    "        return f'TEST PASSED! The {table_name} table exists with {res} number of records'\n",
    "    else:\n",
    "        raise ValueError(f'TEST FAILED! The {table_name} table does not exists with {res} number of records')\n",
    "\n",
    "\n",
    "print('Testing for tables existence.')\n",
    "res1 = exists(dim_temperature, 'dim_temperature')\n",
    "print(res1)\n",
    "res2 = exists(dim_demographic, 'dim_demographic')\n",
    "print(res2)\n",
    "res3 = exists(fact_immigration, 'fact_immigration')\n",
    "print(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dim_temperature.createOrReplaceTempView('dim_temperature')\n",
    "dim_demographic.createOrReplaceTempView('dim_demographic')\n",
    "fact_immigration.createOrReplaceTempView('fact_immigration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for NaNs in primary key columns\n",
      "TEST PASSED! The city column in dim_temperature passed with 0 NaNs\n",
      "TEST PASSED! The date column in dim_temperature passed with 0 NaNs\n",
      "TEST PASSED! The city column in dim_demographic passed with 0 NaNs\n",
      "TEST PASSED! The state_code column in dim_demographic passed with 0 NaNs\n",
      "TEST PASSED! The race column in dim_demographic passed with 0 NaNs\n",
      "TEST PASSED! The id column in fact_immigration passed with 0 NaNs\n"
     ]
    }
   ],
   "source": [
    "# TESTING to see if there are any NaNs in the primary keys\n",
    "\n",
    "dict_of_tables = {'dim_temperature': ['city', 'date'],\n",
    "                  'dim_demographic': ['city', 'state_code', 'race'],\n",
    "                  'fact_immigration': ['id']}\n",
    "\n",
    "\n",
    "def nan_in_column(spark, df_dict):\n",
    "    \"\"\"\n",
    "    Arguments: spark_context, dictionary_of_str_tables_and_columns\n",
    "    \n",
    "    This function counts the number of NaNs in the tables \n",
    "    \"\"\"\n",
    "    for table in df_dict:\n",
    "        for column in df_dict[table]:\n",
    "            \n",
    "            result = spark.sql(f'''SELECT count(*) AS number_of_nans \n",
    "                                   FROM {table} \n",
    "                                   WHERE {column} IS NULL\n",
    "                                   ''')\n",
    "            \n",
    "            if result.head()[0] != 0:\n",
    "                raise ValueError(f\"TEST FAILED! The {column} column in {table} contains {result.head()[0]} NaNs\")\n",
    "            else:\n",
    "                print(f\"TEST PASSED! The {column} column in {table} passed with {result.head()[0]} NaNs\")\n",
    "    \n",
    "\n",
    "print(\"Testing for NaNs in primary key columns\")\n",
    "nan_in_column(spark, dict_of_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "For this data model the columns come from the same dataset as the table name suggest. No joins are made to make these tables.\n",
    "\n",
    "\n",
    "\n",
    "#### Immigration fact table\n",
    "Primary key = id\n",
    "- id = unique id\n",
    "- arrival_city = (string) name of city of arrival by air\n",
    "- arrival_state = (string) name of state of arrival by air\n",
    "- arrival_date = (date) date of arrival\n",
    "- departure_date = (date) date of departure\n",
    "- year = (double) year\n",
    "- month = (double) month\n",
    "- country_citizenship = (string) country citizenship\n",
    "- country_residence = (string) country residence\n",
    "- age = (double) median age\n",
    "- gender = (string) char\n",
    "- reason_for_immigration = (string) category for reason of immigration\n",
    "- visatype = (string) detailed visa type\n",
    "\n",
    "\n",
    "#### Temperature dimension table\n",
    "Primary composite key = city, date\n",
    "- city = (string) name of city\n",
    "- date = (string) date of measurement\n",
    "- year_plus_4_years = (int) year of measurement but with four years added\n",
    "- month = (int) month of measurement\n",
    "- average_temperature = (double) average temperature\n",
    "- average_temperature_uncertainty = (double) average temperature uncertainty\n",
    "\n",
    "\n",
    "#### Demographics dimension table\n",
    "Primary composite key = city, state_code, race\n",
    "- city = (string) name of city\n",
    "- state_code = (string) name of state\n",
    "- race = (string) race\n",
    "- median_age = (double) median age for the city\n",
    "- male_population = (double) male population\n",
    "- total_population = (int) total population\n",
    "- number_of_veterans = (double) number of veterans\n",
    "- foreign_born = (double) foreign born\n",
    "- average_household = (double) average household\n",
    "- count = (int) total respondens of population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 5: Complete Project Write Up\n",
    "* The rationale for the choice of tools and technologies is that Spark and EMR fit perfectly for this project. In my opinion, a notebook like this is pretty necessary to at least set up the ETL. The ETL itself could, of course, be a python script file, which then gets submitted to the EMR cluster, but that is outside of the scope of this project. The built-in parallelization in Spark makes it an ideal tool for working with large amounts of data. \n",
    "\n",
    "\n",
    "#### Scheduling\n",
    "* Since the data is aggregated in months, the ETL should be scheduled to run the first or the second day of every month. \n",
    "\n",
    "\n",
    "#### What would change if the data was increased by 100x?\n",
    "* If the data was increased by 100x, it would still make sense to run a script of the ETL in an AWS EMR. The EMR cluster would need to be larger, and the data would need to be stored in an S3 instead of in the EMR. \n",
    "     \n",
    "\n",
    "#### What would change if the data populates a dashboard that must be updated daily by 7 am every day?\n",
    "* If the ETL needed to run every morning, it would make sense to set up a job in Apache Airflow and schedule it every morning. This would be an easy way to automate the scheduling and the data quality validating. \n",
    "\n",
    "\n",
    "#### What would change if the database needed to be accessed by 100+ people?\n",
    "* The more people accessing the data, the more CPU resources would need to be allocated to give a fast user experience. Instead of increasing the size of the EMR cluster running Spark, it would be more reasonable to write partitioned parquet files to a distributed database, like the Hadoop Distributed File System, HDFS, to secure faster query results for each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
